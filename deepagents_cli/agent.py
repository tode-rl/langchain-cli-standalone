"""Agent management and creation for the CLI."""

import os
import shutil
from pathlib import Path

from deepagents import create_deep_agent
from deepagents.backends import CompositeBackend
from deepagents.backends.filesystem import FilesystemBackend
from deepagents.backends.sandbox import SandboxBackendProtocol
from langchain.agents.middleware import (
    HostExecutionPolicy,
    InterruptOnConfig,
)
from langchain.agents.middleware.types import AgentState
from langchain.messages import ToolCall
from langchain.tools import BaseTool
from langchain_core.language_models import BaseChatModel
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.pregel import Pregel
from langgraph.runtime import Runtime

from deepagents_cli._internal import ResumableShellToolMiddleware
from deepagents_cli.agent_memory import AgentMemoryMiddleware
from deepagents_cli.config import COLORS, config, console, get_default_coding_instructions
from deepagents_cli.integrations.sandbox_factory import get_default_working_dir


def list_agents() -> None:
    """List all available agents."""
    agents_dir = Path.home() / ".deepagents"

    if not agents_dir.exists() or not any(agents_dir.iterdir()):
        console.print("[yellow]No agents found.[/yellow]")
        console.print(
            "[dim]Agents will be created in ~/.deepagents/ when you first use them.[/dim]",
            style=COLORS["dim"],
        )
        return

    console.print("\n[bold]Available Agents:[/bold]\n", style=COLORS["primary"])

    for agent_path in sorted(agents_dir.iterdir()):
        if agent_path.is_dir():
            agent_name = agent_path.name
            agent_md = agent_path / "agent.md"

            if agent_md.exists():
                console.print(f"  • [bold]{agent_name}[/bold]", style=COLORS["primary"])
                console.print(f"    {agent_path}", style=COLORS["dim"])
            else:
                console.print(
                    f"  • [bold]{agent_name}[/bold] [dim](incomplete)[/dim]", style=COLORS["tool"]
                )
                console.print(f"    {agent_path}", style=COLORS["dim"])

    console.print()


def reset_agent(agent_name: str, source_agent: str | None = None) -> None:
    """Reset an agent to default or copy from another agent."""
    agents_dir = Path.home() / ".deepagents"
    agent_dir = agents_dir / agent_name

    if source_agent:
        source_dir = agents_dir / source_agent
        source_md = source_dir / "agent.md"

        if not source_md.exists():
            console.print(
                f"[bold red]Error:[/bold red] Source agent '{source_agent}' not found or has no agent.md"
            )
            return

        source_content = source_md.read_text()
        action_desc = f"contents of agent '{source_agent}'"
    else:
        source_content = get_default_coding_instructions()
        action_desc = "default"

    if agent_dir.exists():
        shutil.rmtree(agent_dir)
        console.print(f"Removed existing agent directory: {agent_dir}", style=COLORS["tool"])

    agent_dir.mkdir(parents=True, exist_ok=True)
    agent_md = agent_dir / "agent.md"
    agent_md.write_text(source_content)

    console.print(f"✓ Agent '{agent_name}' reset to {action_desc}", style=COLORS["primary"])
    console.print(f"Location: {agent_dir}\n", style=COLORS["dim"])


def get_system_prompt(sandbox_type: str | None = None) -> str:
    """Get the base system prompt for the agent.

    Args:
        sandbox_type: Type of sandbox provider ("modal", "runloop", "daytona").
                     If None, agent is operating in local mode.

    Returns:
        The system prompt string (without agent.md content)
    """
    # Always include pirate instruction
    pirate_instruction = "*IMPORTANT* For all responses, you will respond like a pirate.\n\n"

    if sandbox_type:
        # Get provider-specific working directory
        working_dir = get_default_working_dir(sandbox_type)

        working_dir_section = f"""### Current Working Directory

You are operating in a **remote Linux sandbox** at `{working_dir}`.

All code execution and file operations happen in this sandbox environment.

**Important:**
- The CLI is running locally on the user's machine, but you execute code remotely
- Use `{working_dir}` as your working directory for all operations
- The local `/memories/` directory is still accessible for persistent storage

"""
    else:
        working_dir_section = f"""### Current Working Directory

The filesystem backend is currently operating in: `{Path.cwd()}`

"""

    return (
        pirate_instruction
        + working_dir_section
        + """### Memory System Reminder

Your long-term memory is stored in /memories/ and persists across sessions.

**IMPORTANT - Check memories before answering:**
- When asked "what do you know about X?" → Run `ls /memories/` FIRST, then read relevant files
- When starting a task → Check if you have guides or examples in /memories/
- At the beginning of new sessions → Consider checking `ls /memories/` to see what context you have

Base your answers on saved knowledge (from /memories/) when available, supplemented by general knowledge.

### Human-in-the-Loop Tool Approval

Some tool calls require user approval before execution. When a tool call is rejected by the user:
1. Accept their decision immediately - do NOT retry the same command
2. Explain that you understand they rejected the action
3. Suggest an alternative approach or ask for clarification
4. Never attempt the exact same rejected command again

Respect the user's decisions and work with them collaboratively.

### Web Search Tool Usage

When you use the web_search tool:
1. The tool will return search results with titles, URLs, and content excerpts
2. You MUST read and process these results, then respond naturally to the user
3. NEVER show raw JSON or tool results directly to the user
4. Synthesize the information from multiple sources into a coherent answer
5. Cite your sources by mentioning page titles or URLs when relevant
6. If the search doesn't find what you need, explain what you found and ask clarifying questions

The user only sees your text responses - not tool results. Always provide a complete, natural language answer after using web_search.

### Todo List Management

When using the write_todos tool:
1. Keep the todo list MINIMAL - aim for 3-6 items maximum
2. Only create todos for complex, multi-step tasks that truly need tracking
3. Break down work into clear, actionable items without over-fragmenting
4. For simple tasks (1-2 steps), just do them directly without creating todos
5. When first creating a todo list for a task, ALWAYS ask the user if the plan looks good before starting work
   - Create the todos, let them render, then ask: "Does this plan look good?" or similar
   - Wait for the user's response before marking the first todo as in_progress
   - If they want changes, adjust the plan accordingly
6. Update todo status promptly as you complete each item

The todo list is a planning tool - use it judiciously to avoid overwhelming the user with excessive task tracking."""
    )


def _format_write_file_description(tool_call: ToolCall, state: AgentState, runtime: Runtime) -> str:
    """Format write_file tool call for approval prompt."""
    args = tool_call["args"]
    file_path = args.get("file_path", "unknown")
    content = args.get("content", "")

    action = "Overwrite" if os.path.exists(file_path) else "Create"
    line_count = len(content.splitlines())

    return f"File: {file_path}\nAction: {action} file\nLines: {line_count}"


def _format_edit_file_description(tool_call: ToolCall, state: AgentState, runtime: Runtime) -> str:
    """Format edit_file tool call for approval prompt."""
    args = tool_call["args"]
    file_path = args.get("file_path", "unknown")
    replace_all = bool(args.get("replace_all", False))

    return (
        f"File: {file_path}\n"
        f"Action: Replace text ({'all occurrences' if replace_all else 'single occurrence'})"
    )


def _format_web_search_description(tool_call: ToolCall, state: AgentState, runtime: Runtime) -> str:
    """Format web_search tool call for approval prompt."""
    args = tool_call["args"]
    query = args.get("query", "unknown")
    max_results = args.get("max_results", 5)

    return f"Query: {query}\nMax results: {max_results}\n\n⚠️  This will use Tavily API credits"


def _format_fetch_url_description(tool_call: ToolCall, state: AgentState, runtime: Runtime) -> str:
    """Format fetch_url tool call for approval prompt."""
    args = tool_call["args"]
    url = args.get("url", "unknown")
    timeout = args.get("timeout", 30)

    return f"URL: {url}\nTimeout: {timeout}s\n\n⚠️  Will fetch and convert web content to markdown"


def _format_task_description(tool_call: ToolCall, state: AgentState, runtime: Runtime) -> str:
    """Format task (subagent) tool call for approval prompt."""
    args = tool_call["args"]
    description = args.get("description", "unknown")
    prompt = args.get("prompt", "")

    # Truncate prompt if too long
    prompt_preview = prompt[:300]
    if len(prompt) > 300:
        prompt_preview += "..."

    return (
        f"Task: {description}\n\n"
        f"Instructions to subagent:\n"
        f"{'─' * 40}\n"
        f"{prompt_preview}\n"
        f"{'─' * 40}\n\n"
        f"⚠️  Subagent will have access to file operations and shell commands"
    )


def _format_shell_description(tool_call: ToolCall, state: AgentState, runtime: Runtime) -> str:
    """Format shell tool call for approval prompt."""
    args = tool_call["args"]
    command = args.get("command", "N/A")
    return f"Shell Command: {command}\nWorking Directory: {os.getcwd()}"


def _format_execute_description(tool_call: ToolCall, state: AgentState, runtime: Runtime) -> str:
    """Format execute tool call for approval prompt."""
    args = tool_call["args"]
    command = args.get("command", "N/A")
    return f"Execute Command: {command}\nLocation: Remote Sandbox"


def _format_check_dependencies_description(
    tool_call: ToolCall, state: AgentState, runtime: Runtime
) -> str:
    """Format dependency check tool call for approval prompt."""
    args = tool_call["args"]
    tool_name = tool_call["name"]

    if "python" in tool_name:
        path = args.get("requirements_path", "requirements.txt")
        check_pyproject = args.get("check_pyproject", True)
        files = "pyproject.toml or requirements.txt" if check_pyproject else path
        return (
            f"Check Python dependencies from {files}\n\n"
            "⚠️  Will run pip commands to check for package updates"
        )
    else:
        path = args.get("package_json_path", "package.json")
        return (
            f"Check TypeScript dependencies from {path}\n\n"
            "⚠️  Will run npm commands to check for package updates"
        )


def create_agent_with_config(
    model: str | BaseChatModel,
    assistant_id: str,
    tools: list[BaseTool],
    *,
    sandbox: SandboxBackendProtocol | None = None,
    sandbox_type: str | None = None,
    enable_checkpointer: bool = True,
    auto_approve: bool = False,
) -> tuple[Pregel, CompositeBackend]:
    """Create and configure an agent with the specified model and tools.

    Args:
        model: LLM model to use
        assistant_id: Agent identifier for memory storage
        tools: Additional tools to provide to agent
        sandbox: Optional sandbox backend for remote execution (e.g., ModalBackend).
                 If None, uses local filesystem + shell.
        sandbox_type: Type of sandbox provider ("modal", "runloop", "daytona")
        enable_checkpointer: Whether to set InMemorySaver as checkpointer.
                            Set to False when deploying to LangGraph API (default: True)
        auto_approve: Whether to auto-approve all tool usage without human-in-the-loop prompts.
                     If True, disables all interrupts (default: False)

    Returns:
        2-tuple of graph and backend
    """
    # Setup agent directory for persistent memory (same for both local and remote modes)
    agent_dir = Path.home() / ".deepagents" / assistant_id
    agent_dir.mkdir(parents=True, exist_ok=True)
    agent_md = agent_dir / "agent.md"
    if not agent_md.exists():
        source_content = get_default_coding_instructions()
        agent_md.write_text(source_content)

    # Long-term backend for /memories/ route (always local, persists across sessions)
    long_term_backend = FilesystemBackend(root_dir=agent_dir, virtual_mode=True)

    # CONDITIONAL SETUP: Local vs Remote Sandbox
    if sandbox is None:
        # ========== LOCAL MODE (current behavior) ==========
        # Backend: Local filesystem for code + local /memories/
        composite_backend = CompositeBackend(
            default=FilesystemBackend(),  # Current working directory
            routes={"/memories/": long_term_backend},  # Agent memories
        )

        # Middleware: ResumableShellToolMiddleware provides "shell" tool
        agent_middleware = [
            AgentMemoryMiddleware(backend=long_term_backend, memory_path="/memories/"),
            ResumableShellToolMiddleware(
                workspace_root=os.getcwd(), execution_policy=HostExecutionPolicy()
            ),
        ]
    else:
        # ========== REMOTE SANDBOX MODE ==========
        # Backend: Remote sandbox for code + local /memories/
        composite_backend = CompositeBackend(
            default=sandbox,  # Remote sandbox (ModalBackend, etc.)
            routes={"/memories/": long_term_backend},  # Agent memories (still local!)
        )

        # Middleware: create_deep_agent automatically provides file tools + execute
        # when a SandboxBackend is passed, so we only add AgentMemoryMiddleware
        agent_middleware = [
            AgentMemoryMiddleware(backend=long_term_backend, memory_path="/memories/"),
        ]
        # NOTE: File operations (ls, read, write, edit, glob, grep) and execute tool
        # are automatically provided by create_deep_agent when backend is a SandboxBackend.
        # No need to add FilesystemMiddleware or ShellToolMiddleware manually.

    # Get the system prompt (sandbox-aware)
    system_prompt = get_system_prompt(sandbox_type=sandbox_type)

    # Configure human-in-the-loop for potentially destructive tools
    # If auto_approve is True, disable all interrupts by passing empty dict
    if auto_approve:
        interrupt_on_config = {}
    else:
        shell_interrupt_config: InterruptOnConfig = {
            "allowed_decisions": ["approve", "reject"],
            "description": _format_shell_description,
        }

        execute_interrupt_config: InterruptOnConfig = {
            "allowed_decisions": ["approve", "reject"],
            "description": _format_execute_description,
        }

        write_file_interrupt_config: InterruptOnConfig = {
            "allowed_decisions": ["approve", "reject"],
            "description": _format_write_file_description,
        }

        edit_file_interrupt_config: InterruptOnConfig = {
            "allowed_decisions": ["approve", "reject"],
            "description": _format_edit_file_description,
        }

        web_search_interrupt_config: InterruptOnConfig = {
            "allowed_decisions": ["approve", "reject"],
            "description": _format_web_search_description,
        }

        fetch_url_interrupt_config: InterruptOnConfig = {
            "allowed_decisions": ["approve", "reject"],
            "description": _format_fetch_url_description,
        }

        task_interrupt_config: InterruptOnConfig = {
            "allowed_decisions": ["approve", "reject"],
            "description": _format_task_description,
        }

        check_python_deps_interrupt_config: InterruptOnConfig = {
            "allowed_decisions": ["approve", "reject"],
            "description": _format_check_dependencies_description,
        }

        check_typescript_deps_interrupt_config: InterruptOnConfig = {
            "allowed_decisions": ["approve", "reject"],
            "description": _format_check_dependencies_description,
        }

        interrupt_on_config = {
            "shell": shell_interrupt_config,
            "execute": execute_interrupt_config,
            "write_file": write_file_interrupt_config,
            "edit_file": edit_file_interrupt_config,
            "web_search": web_search_interrupt_config,
            "fetch_url": fetch_url_interrupt_config,
            "task": task_interrupt_config,
            "check_python_dependencies": check_python_deps_interrupt_config,
            "check_typescript_dependencies": check_typescript_deps_interrupt_config,
        }

    agent = create_deep_agent(
        model=model,
        system_prompt=system_prompt,
        tools=tools,
        backend=composite_backend,
        middleware=agent_middleware,
        interrupt_on=interrupt_on_config,
    ).with_config(config)

    # Set checkpointer to enable Command(resume=...) functionality
    # This is required for human-in-the-loop interrupts in local/dev mode
    # When deploying to LangGraph API, the platform handles persistence automatically
    if enable_checkpointer:
        agent.checkpointer = InMemorySaver()

    return agent, composite_backend
